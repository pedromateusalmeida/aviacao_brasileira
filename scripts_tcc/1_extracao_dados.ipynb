{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc58dd4f-f578-4c33-b911-e7820bc59d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c88b0780-a630-4384-8f80-5f9a0a1e9eeb",
   "metadata": {},
   "source": [
    "# Pacotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26627663-d669-43b0-84ba-7f8c9fc934cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4706462e-067e-423b-9821-4980d480356e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importações da biblioteca padrão\n",
    "import os\n",
    "import time\n",
    " \n",
    "# Importações de terceiros para raspagem de dados na web\n",
    "import requests\n",
    "from requests.adapters import HTTPAdapter\n",
    "from requests.packages.urllib3.util.retry import Retry\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Manipulação de dados\n",
    "import pandas as pd\n",
    "\n",
    "# Trabalhar com arquivos zip\n",
    "import zipfile\n",
    "\n",
    "from concurrent.futures import ThreadPoolExecutor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4ada4c8-ccc6-431f-84b1-c15c42c3fbe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "os: os\n",
      "time: time\n",
      "requests: 2.31.0\n",
      "bs4: 4.12.2\n",
      "pandas: 2.1.4\n",
      "zipfile: Built-in library (version included in Python)\n",
      "concurrent.futures: Built-in library (version included in Python)\n"
     ]
    }
   ],
   "source": [
    "# Bibliotecas padrão\n",
    "import os\n",
    "import time\n",
    "\n",
    "# Bibliotecas de terceiros para raspagem de dados na web\n",
    "import requests\n",
    "from requests.adapters import HTTPAdapter\n",
    "from requests.packages.urllib3.util.retry import Retry\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Manipulação de dados\n",
    "import pandas as pd\n",
    "\n",
    "# Trabalhar com arquivos zip\n",
    "import zipfile\n",
    "\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "# Dicionário com as bibliotecas e seus métodos de versão\n",
    "libraries = {\n",
    "    \"os\": os.__name__,\n",
    "    \"time\": time.__name__,\n",
    "    \"requests\": requests.__version__,\n",
    "    \"bs4\": bs4.__version__,  # A versão vem do módulo bs4, não de BeautifulSoup\n",
    "    \"pandas\": pd.__version__,\n",
    "    \"zipfile\": \"Built-in library (version included in Python)\",\n",
    "    \"concurrent.futures\": \"Built-in library (version included in Python)\"\n",
    "}\n",
    "\n",
    "# Printando a versão de cada biblioteca\n",
    "for lib, version in libraries.items():\n",
    "    print(f\"{lib}: {version}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4baa8b6-3bd1-442b-a7a5-d80944d4824e",
   "metadata": {},
   "source": [
    "# Funções"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "730cf0c9-2952-4369-8912-b9eab8eef82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_csv_files(year):\n",
    "    \"\"\"\n",
    "    Faz o download de arquivos CSV de dados históricos de voos para o ano especificado a partir do site da ANAC.\n",
    "\n",
    "    Args:\n",
    "    year (int): O ano para o qual os dados devem ser baixados.\n",
    "\n",
    "    Etapas:\n",
    "    1. Configurar uma sessão de requests com regras de nova tentativa em caso de falhas.\n",
    "    2. Realizar uma requisição GET para a URL base e usar BeautifulSoup para analisar o conteúdo HTML.\n",
    "    3. Criar um diretório para o ano especificado, se não existir.\n",
    "    4. Mapear os meses em português para códigos numéricos e encontrar a seção correspondente ao ano desejado.\n",
    "    5. Iterar sobre os meses, localizar os links de download dos arquivos CSV, e fazer o download de cada arquivo.\n",
    "    6. Em caso de falha no download, registrar a exceção.\n",
    "    7. Pausar por 7 segundos entre os downloads para evitar sobrecarga do servidor.\n",
    "\n",
    "    Returns:\n",
    "    None. Os arquivos são salvos localmente.\n",
    "    \"\"\"\n",
    "    mouth = [\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\", \"10\", \"11\",\"12\"]\n",
    "    # Definição da URL base para os dados climáticos do ano especificado.\n",
    "    base_url = f\"https://portal.inmet.gov.br/uploads/dadoshistoricos/{year}/VRA_{year}_{mouth}.csv\"\n",
    "\n",
    "    # Configuração de uma sessão HTTP com regras de retry para lidar com falhas de conexão ou timeouts.\n",
    "    session = requests.Session()\n",
    "    retries = Retry(total=5, backoff_factor=1, status_forcelist=[502, 503, 504])\n",
    "    session.mount('https://', HTTPAdapter(max_retries=retries))\n",
    "\n",
    "    # Requisição GET para a URL base.\n",
    "    response = session.get(base_url)\n",
    "    # Uso de BeautifulSoup para parsear a resposta HTML.\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    # Criação do diretório para o ano especificado, se não existir.\n",
    "    os.makedirs(str(year), exist_ok=True)\n",
    "\n",
    "    # Mapeamento dos meses em português para o formato numérico padrão.\n",
    "    month_mapping = {\n",
    "        'Janeiro': '01', 'Fevereiro': '02', 'Março': '03', 'Abril': '04', 'Maio': '05', 'Junho': '06',\n",
    "        'Julho': '07', 'Agosto': '08', 'Setembro': '09', 'Outubro': '10', 'Novembro': '11', 'Dezembro': '12'\n",
    "    }\n",
    "\n",
    "    # Localização da seção do ano especificado no HTML.\n",
    "    year_section = soup.find('h2', string=str(year))\n",
    "    if not year_section:\n",
    "        print(f\"Ano {year} não encontrado na página.\")\n",
    "        return\n",
    "\n",
    "    # Iteração sobre os meses para encontrar e fazer download dos arquivos CSV.\n",
    "    for month, month_code in month_mapping.items():\n",
    "        link = year_section.find_next('a', string=month, href=True)\n",
    "        if link:\n",
    "            file_url = link['href']\n",
    "            local_file_name = f\"{year}/vra-{month_code}_{year}.csv\"\n",
    "            try:\n",
    "                # Requisição GET para o arquivo CSV e gravação do conteúdo no arquivo local.\n",
    "                file_response = session.get(file_url)\n",
    "                file_response.raise_for_status()\n",
    "                with open(local_file_name, 'wb') as file:\n",
    "                    file.write(file_response.content)\n",
    "                print(f\"Downloaded {local_file_name}\")\n",
    "            except requests.exceptions.RequestException as e:\n",
    "                print(f\"Failed to download {file_url}: {e}\")\n",
    "        else:\n",
    "            print(f\"Link para {month} não encontrado.\")\n",
    "\n",
    "        # Pausa entre downloads para não sobrecarregar o servidor.\n",
    "        time.sleep(10)\n",
    "\n",
    "def download_dados_complementares(file_to_download=None):\n",
    "    \"\"\"\n",
    "    Faz o download e a conversão de arquivos complementares relacionados a dados de voos.\n",
    "    \n",
    "    Etapas:\n",
    "    1. Definir as URLs dos arquivos para download e os nomes dos arquivos.\n",
    "    2. Criar diretórios para armazenar os arquivos baixados e convertidos, se não existirem.\n",
    "    3. Fazer o download de cada arquivo .xls e salvar localmente.\n",
    "    4. Converter cada arquivo .xls baixado em um arquivo .csv, ajustando as colunas conforme necessário.\n",
    "    5. Em caso de falha no download ou na conversão, registrar a exceção.\n",
    "    \n",
    "    Args:\n",
    "    file_to_download: Nome opcional do arquivo específico a ser baixado. Se None, todos os arquivos serão baixados.\n",
    "    \n",
    "    Returns:\n",
    "    None. Os arquivos são salvos e convertidos localmente.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Definição das URLs dos arquivos de dados complementares e seus respectivos nomes.\n",
    "    urls = {\n",
    "        \"https://www.gov.br/anac/pt-br/assuntos/dados-e-estatisticas/vra/glossario_de_aerodromo.xls\": \"glossario_de_aerodromo\",\n",
    "        \"https://www.gov.br/anac/pt-br/assuntos/dados-e-estatisticas/vra/glossario_de_empresas_aereas.xls\": \"glossario_de_empresas_aereas\",\n",
    "        \"https://sistemas.anac.gov.br/dadosabertos/Aerodromos/Aeródromos%20Públicos/Lista%20de%20aeródromos%20públicos/AerodromosPublicos.csv\": \"aerodromos_brasil\"\n",
    "    }\n",
    "\n",
    "    # Filtrar o dicionário de URLs se um arquivo específico for requisitado.\n",
    "    if file_to_download:\n",
    "        urls = {url: name for url, name in urls.items() if name == file_to_download}\n",
    "\n",
    "    # Caminhos para os diretórios onde os arquivos serão salvos.\n",
    "    dir_path = \"dados_complementares\"\n",
    "\n",
    "    # Criação do diretório, se ele não existir.\n",
    "    if not os.path.exists(dir_path):\n",
    "        os.makedirs(dir_path)\n",
    "\n",
    "    # Processo de download e conversão dos arquivos.\n",
    "    for url, file_name in urls.items():\n",
    "        # Caminho do arquivo a ser baixado.\n",
    "        file_path = os.path.join(dir_path, f\"{file_name}\")\n",
    "        response = requests.get(url)\n",
    "        if response.status_code == 200:\n",
    "            # Verifica a extensão do arquivo para decidir o processo de salvamento.\n",
    "            if url.lower().endswith('.xls'):\n",
    "                # Se o arquivo é um .xls, salva e converte para .csv.\n",
    "                file_path += '.xls'\n",
    "                with open(file_path, 'wb') as file:\n",
    "                    file.write(response.content)\n",
    "                print(f\"Downloaded {file_path}\")\n",
    "\n",
    "                # Tentativa de conversão do arquivo .xls para .csv.\n",
    "                try:\n",
    "                    # Carregamento e limpeza dos dados do arquivo .xls.\n",
    "                    df = pd.read_excel(file_path, header=3)\n",
    "                    df.drop(columns=[col for col in df.columns if 'Unnamed' in col], inplace=True)\n",
    "\n",
    "                    # Caminho do arquivo .csv convertido.\n",
    "                    csv_path = file_path.replace('.xls', '.csv')\n",
    "                    # Salvando os dados limpos em formato .csv.\n",
    "                    df.to_csv(csv_path, index=False)\n",
    "                    print(f\"Converted to {csv_path}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Error converting {file_path} to CSV: {e}\")\n",
    "            elif url.lower().endswith('.csv'):\n",
    "                # Se o arquivo já é um .csv, apenas salva.\n",
    "                file_path += '.csv'\n",
    "                with open(file_path, 'wb') as file:\n",
    "                    file.write(response.content)\n",
    "                print(f\"Downloaded {file_path}\")\n",
    "        else:\n",
    "            print(f\"Failed to download {url}\")\n",
    "\n",
    "\n",
    "def download_and_extract_climate_data(year):\n",
    "    \"\"\"\n",
    "    Realiza o download de arquivos ZIP de dados climáticos de um ano específico a partir do portal do INMET\n",
    "    e extrai os conteúdos para uma pasta nomeada 'CLIMA_<ANO>'.\n",
    "\n",
    "    Args:\n",
    "    year (int): O ano dos dados climáticos a serem baixados.\n",
    "\n",
    "    Etapas:\n",
    "    1. Configurar uma sessão de requests com regras de retry para lidar com falhas de conexão ou timeouts.\n",
    "    2. Construir a URL do arquivo ZIP para o ano especificado.\n",
    "    3. Criar um diretório para armazenar os dados desse ano, se não existir.\n",
    "    4. Realizar o download do arquivo ZIP.\n",
    "    5. Extrair o conteúdo do arquivo ZIP no diretório criado.\n",
    "    6. Lidar com falhas no download ou na extração, registrando exceções.\n",
    "    7. Aguardar um intervalo entre downloads para evitar sobrecarga do servidor.\n",
    "\n",
    "    Returns:\n",
    "    None. Os arquivos são baixados e extraídos localmente.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Definição da URL base para os dados climáticos do ano especificado.\n",
    "    base_url = f\"https://portal.inmet.gov.br/uploads/dadoshistoricos/{year}.zip\"\n",
    "\n",
    "    # Configuração de sessão HTTP com políticas de retry.\n",
    "    session = requests.Session()\n",
    "    retries = Retry(total=5, backoff_factor=1, status_forcelist=[502, 503, 504])\n",
    "    session.mount('https://', HTTPAdapter(max_retries=retries))\n",
    "\n",
    "    # Criação do diretório para armazenar os dados do ano.\n",
    "    directory_name = f\"DADOS_METEROLOGIA/CLIMA_{year}\"\n",
    "    os.makedirs(directory_name, exist_ok=True)\n",
    "\n",
    "    # Nome do arquivo ZIP local.\n",
    "    local_zip_file = f\"{directory_name}/{year}.zip\"\n",
    "    \n",
    "    try:\n",
    "        # Download do arquivo ZIP.\n",
    "        print(f\"Iniciando download do arquivo {year}.zip...\")\n",
    "        zip_response = session.get(base_url)\n",
    "        zip_response.raise_for_status()\n",
    "\n",
    "        # Salvar o conteúdo do ZIP no arquivo local.\n",
    "        with open(local_zip_file, 'wb') as file:\n",
    "            file.write(zip_response.content)\n",
    "        print(f\"Download do arquivo {year}.zip concluído.\")\n",
    "\n",
    "        # Extração do conteúdo do arquivo ZIP.\n",
    "        with zipfile.ZipFile(local_zip_file, 'r') as zip_ref:\n",
    "            zip_ref.extractall(directory_name)\n",
    "        print(f\"Arquivos extraídos para a pasta {directory_name}.\")\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Falha no download do arquivo {year}.zip: {e}\")\n",
    "\n",
    "    except zipfile.BadZipFile as e:\n",
    "        print(f\"Falha ao extrair o arquivo {year}.zip: {e}\")\n",
    "\n",
    "    # Remoção do arquivo ZIP após a extração.\n",
    "    os.remove(local_zip_file)\n",
    "    print(f\"Arquivo ZIP {local_zip_file} removido.\")\n",
    "\n",
    "    # Intervalo entre downloads para evitar sobrecarga do servidor.\n",
    "    time.sleep(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "419df2cc-4b70-4cbb-a357-de7fbc38c113",
   "metadata": {},
   "source": [
    "# Extração"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "46572fe2-3946-4b2b-83a2-e56aa44fe87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_csv_files(year):\n",
    "    \"\"\"\n",
    "    Faz o download dos arquivos CSV de dados históricos de voos da ANAC para um ano específico.\n",
    "    \n",
    "    Args:\n",
    "        year (int): Ano desejado para download dos dados.\n",
    "    \n",
    "    Etapas:\n",
    "    1. Configura a sessão HTTP com política de retries.\n",
    "    2. Define a URL base e gera URLs corretas para cada mês.\n",
    "    3. Cria diretório local para armazenar os arquivos.\n",
    "    4. Faz o download de cada arquivo mensal.\n",
    "    5. Trata exceções e aguarda entre downloads.\n",
    "    \n",
    "    Returns:\n",
    "        None. Arquivos salvos localmente.\n",
    "    \"\"\"\n",
    "\n",
    "    # URL base para downloads (ANAC)\n",
    "    base_url = f\"https://siros.anac.gov.br/siros/registros/diversos/vra/{year}/\"\n",
    "\n",
    "    # Sessão HTTP com retries configurados\n",
    "    session = requests.Session()\n",
    "    retries = Retry(total=5, backoff_factor=2, status_forcelist=[500, 502, 503, 504])\n",
    "    session.mount('https://', HTTPAdapter(max_retries=retries))\n",
    "    session.mount('http://', HTTPAdapter(max_retries=retries))\n",
    "\n",
    "    # Criação do diretório para o ano especificado\n",
    "    directory = str(year)\n",
    "    os.makedirs(directory, exist_ok=True)\n",
    "\n",
    "    # Iteração pelos 12 meses\n",
    "    for month in range(1, 13):\n",
    "        month_code = str(month).zfill(2)  # Formato '01', '02', ..., '12'\n",
    "        file_name = f\"VRA_{year}_{month_code}.csv\"\n",
    "        file_url = f\"{base_url}{file_name}\"\n",
    "        local_file_path = os.path.join(directory, file_name)\n",
    "\n",
    "        try:\n",
    "            response = session.get(file_url)\n",
    "            response.raise_for_status()  # Garante que houve sucesso no download\n",
    "            \n",
    "            # Salva o arquivo localmente\n",
    "            with open(local_file_path, 'wb') as file:\n",
    "                file.write(response.content)\n",
    "\n",
    "            print(f\"Downloaded: {local_file_path}\")\n",
    "\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Erro ao baixar {file_url}: {e}\")\n",
    "\n",
    "        # Aguarda 7 segundos para evitar sobrecarga do servidor\n",
    "        time.sleep(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "40d685bd-0286-4515-b44d-c5868db8e104",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded: 2024\\VRA_2024_01.csv\n",
      "Downloaded: 2024\\VRA_2024_02.csv\n",
      "Downloaded: 2024\\VRA_2024_03.csv\n",
      "Downloaded: 2024\\VRA_2024_04.csv\n",
      "Downloaded: 2024\\VRA_2024_05.csv\n",
      "Downloaded: 2024\\VRA_2024_06.csv\n",
      "Downloaded: 2024\\VRA_2024_07.csv\n",
      "Downloaded: 2024\\VRA_2024_08.csv\n",
      "Downloaded: 2024\\VRA_2024_09.csv\n",
      "Downloaded: 2024\\VRA_2024_10.csv\n",
      "Downloaded: 2024\\VRA_2024_11.csv\n",
      "Downloaded: 2024\\VRA_2024_12.csv\n"
     ]
    }
   ],
   "source": [
    "# Exemplo de uso:\n",
    "download_csv_files(2024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0250c322-af7b-443d-b273-b70afed15ec6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded 2023/vra-01_2023.csv\n",
      "Downloaded 2023/vra-02_2023.csv\n",
      "Downloaded 2023/vra-03_2023.csv\n",
      "Downloaded 2023/vra-04_2023.csv\n",
      "Downloaded 2023/vra-05_2023.csv\n",
      "Downloaded 2023/vra-06_2023.csv\n",
      "Downloaded 2023/vra-07_2023.csv\n",
      "Downloaded 2023/vra-08_2023.csv\n",
      "Downloaded 2023/vra-09_2023.csv\n",
      "Downloaded 2023/vra-10_2023.csv\n",
      "Downloaded 2023/vra-11_2023.csv\n",
      "Downloaded 2023/vra-12_2023.csv\n"
     ]
    }
   ],
   "source": [
    "# Chamar a função para o ano de 2018\n",
    "download_csv_files(2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51ed1707-89df-4f3f-95ab-c257ad63e97f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded dados_complementares\\glossario_de_aerodromo.xls\n",
      "Converted to dados_complementares\\glossario_de_aerodromo.csv\n",
      "Downloaded dados_complementares\\glossario_de_empresas_aereas.xls\n",
      "Converted to dados_complementares\\glossario_de_empresas_aereas.csv\n",
      "Downloaded dados_complementares\\aerodromos_brasil.csv\n"
     ]
    }
   ],
   "source": [
    "# Executar a função\n",
    "download_dados_complementares()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9d07d2f2-58e9-4292-8040-55b35e9b8556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando download do arquivo 2024.zip...\n",
      "Download do arquivo 2024.zip concluído.\n",
      "Arquivos extraídos para a pasta DADOS_METEROLOGIA/CLIMA_2024.\n",
      "Arquivo ZIP DADOS_METEROLOGIA/CLIMA_2024/2024.zip removido.\n"
     ]
    }
   ],
   "source": [
    "# Exemplo de uso da função\n",
    "download_and_extract_climate_data(2024)  # Altere para o ano desejado."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "078ca044-4e3d-43ac-99f1-e8dd0482fd2a",
   "metadata": {},
   "source": [
    "# Utilizando as funções acima para extrair mais de um ano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55117c7e-e1c6-4da5-a081-6db9e39023de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded 2018/vra-01_2018.csv\n",
      "Downloaded 2020/vra-01_2020.csv\n",
      "Downloaded 2019/vra-01_2019.csv\n",
      "Downloaded 2018/vra-02_2018.csv\n",
      "Downloaded 2019/vra-02_2019.csv\n",
      "Downloaded 2020/vra-02_2020.csv\n",
      "Downloaded 2018/vra-03_2018.csv\n",
      "Downloaded 2019/vra-03_2019.csv\n",
      "Downloaded 2020/vra-03_2020.csv\n",
      "Downloaded 2018/vra-04_2018.csv\n",
      "Downloaded 2019/vra-04_2019.csv\n",
      "Downloaded 2020/vra-04_2020.csv\n",
      "Downloaded 2018/vra-05_2018.csv\n",
      "Downloaded 2020/vra-05_2020.csv\n",
      "Downloaded 2019/vra-05_2019.csv\n",
      "Failed to download https://www.gov.br/anac/pt-br/assuntos/dados-e-estatisticas/percentuais-de-atrasos-e-cancelamentos-2/2018/vra_062018.csv: (\"Connection broken: InvalidChunkLength(got length b'', 0 bytes read)\", InvalidChunkLength(got length b'', 0 bytes read))\n",
      "Downloaded 2020/vra-06_2020.csv\n",
      "Downloaded 2019/vra-06_2019.csv\n",
      "Downloaded 2020/vra-07_2020.csv\n",
      "Downloaded 2018/vra-07_2018.csv\n",
      "Downloaded 2019/vra-07_2019.csv\n",
      "Downloaded 2020/vra-08_2020.csv\n",
      "Downloaded 2018/vra-08_2018.csv\n",
      "Downloaded 2019/vra-08_2019.csv\n",
      "Downloaded 2020/vra-09_2020.csv\n",
      "Downloaded 2018/vra-09_2018.csv\n",
      "Downloaded 2019/vra-09_2019.csv\n",
      "Downloaded 2020/vra-10_2020.csv\n",
      "Downloaded 2018/vra-10_2018.csv\n",
      "Downloaded 2019/vra-10_2019.csv\n",
      "Downloaded 2020/vra-11_2020.csv\n",
      "Downloaded 2018/vra-11_2018.csv\n",
      "Downloaded 2019/vra-11_2019.csv\n",
      "Downloaded 2020/vra-12_2020.csv\n",
      "Downloaded 2018/vra-12_2018.csv\n",
      "Downloaded 2019/vra-12_2019.csv\n",
      "Downloaded 2021/vra-01_2021.csv\n",
      "Downloaded 2022/vra-01_2022.csv\n",
      "Downloaded 2023/vra-01_2023.csv\n",
      "Downloaded 2021/vra-02_2021.csv\n",
      "Downloaded 2022/vra-02_2022.csv\n",
      "Downloaded 2023/vra-02_2023.csv\n",
      "Downloaded 2021/vra-03_2021.csv\n",
      "Downloaded 2022/vra-03_2022.csv\n",
      "Downloaded 2023/vra-03_2023.csv\n",
      "Downloaded 2021/vra-04_2021.csv\n",
      "Downloaded 2022/vra-04_2022.csv\n",
      "Downloaded 2023/vra-04_2023.csv\n",
      "Downloaded 2021/vra-05_2021.csv\n",
      "Downloaded 2022/vra-05_2022.csv\n",
      "Downloaded 2023/vra-05_2023.csv\n",
      "Downloaded 2021/vra-06_2021.csv\n",
      "Downloaded 2022/vra-06_2022.csv\n",
      "Downloaded 2023/vra-06_2023.csv\n",
      "Downloaded 2021/vra-07_2021.csv\n",
      "Downloaded 2022/vra-07_2022.csv\n",
      "Downloaded 2021/vra-08_2021.csv\n",
      "Downloaded 2023/vra-07_2023.csv\n",
      "Downloaded 2021/vra-09_2021.csv\n",
      "Downloaded 2022/vra-08_2022.csv\n",
      "Downloaded 2023/vra-08_2023.csv\n",
      "Downloaded 2021/vra-10_2021.csv\n",
      "Downloaded 2022/vra-09_2022.csv\n",
      "Downloaded 2023/vra-09_2023.csv\n",
      "Downloaded 2021/vra-11_2021.csv\n",
      "Downloaded 2022/vra-10_2022.csv\n",
      "Downloaded 2023/vra-10_2023.csv\n",
      "Downloaded 2021/vra-12_2021.csv\n",
      "Downloaded 2022/vra-11_2022.csv\n",
      "Downloaded 2023/vra-11_2023.csv\n",
      "Downloaded 2023/vra-12_2023.csv\n",
      "Downloaded 2022/vra-12_2022.csv\n"
     ]
    }
   ],
   "source": [
    "# Lista dos anos para os quais você deseja baixar os dados\n",
    "years = [2018, 2019, 2020,2021,2022,2023]\n",
    "\n",
    "# Usando ThreadPoolExecutor para baixar arquivos CSV de dados históricos de voos\n",
    "with ThreadPoolExecutor(max_workers=3) as executor:\n",
    "    executor.map(download_csv_files, years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "78a3f1fe-5bac-45a9-a042-0194eb3723e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando download do arquivo 2018.zip...\n",
      "Iniciando download do arquivo 2019.zip...\n",
      "Iniciando download do arquivo 2020.zip...\n",
      "Download do arquivo 2018.zip concluído.\n",
      "Arquivos extraídos para a pasta DADOS_METEROLOGIA/CLIMA_2018.\n",
      "Arquivo ZIP DADOS_METEROLOGIA/CLIMA_2018/2018.zip removido.\n",
      "Iniciando download do arquivo 2021.zip...\n",
      "Download do arquivo 2020.zip concluído.\n",
      "Arquivos extraídos para a pasta DADOS_METEROLOGIA/CLIMA_2020.\n",
      "Arquivo ZIP DADOS_METEROLOGIA/CLIMA_2020/2020.zip removido.\n",
      "Iniciando download do arquivo 2022.zip...\n",
      "Download do arquivo 2021.zip concluído.\n",
      "Arquivos extraídos para a pasta DADOS_METEROLOGIA/CLIMA_2021.\n",
      "Arquivo ZIP DADOS_METEROLOGIA/CLIMA_2021/2021.zip removido.\n",
      "Download do arquivo 2019.zip concluído.\n",
      "Arquivos extraídos para a pasta DADOS_METEROLOGIA/CLIMA_2019.\n",
      "Arquivo ZIP DADOS_METEROLOGIA/CLIMA_2019/2019.zip removido.\n",
      "Iniciando download do arquivo 2023.zip...\n",
      "Download do arquivo 2022.zip concluído.\n",
      "Arquivos extraídos para a pasta DADOS_METEROLOGIA/CLIMA_2022.\n",
      "Arquivo ZIP DADOS_METEROLOGIA/CLIMA_2022/2022.zip removido.\n",
      "Download do arquivo 2023.zip concluído.\n",
      "Arquivos extraídos para a pasta DADOS_METEROLOGIA/CLIMA_2023.\n",
      "Arquivo ZIP DADOS_METEROLOGIA/CLIMA_2023/2023.zip removido.\n"
     ]
    }
   ],
   "source": [
    "# Usando ThreadPoolExecutor para baixar e extrair dados climáticos\n",
    "with ThreadPoolExecutor(max_workers=3) as executor:\n",
    "    executor.map(download_and_extract_climate_data, years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e48a01-9ba3-45a2-94e2-877162373294",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
