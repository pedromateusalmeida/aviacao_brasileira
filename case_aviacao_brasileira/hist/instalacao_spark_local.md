<div style="text-align: justify">
A intenção neste segmento não é detalhar o passo a passo da instalação do Spark, uma vez que há uma vasta gama de recursos disponíveis online que já abordam este tópico de maneira competente. Neste espaço, busco fazer observações específicas sobre as precauções a serem tomadas durante o processo de instalação e configuração. Se você está em busca de instruções detalhadas, vou listar alguns sites que considerei úteis ao realizar minha própria instalação.
<br />
<br />
<strong>O que preciso baixar?</strong><br /><br />
</div>
- [Spark - Apache Official](https://spark.apache.org/downloads.html)<br />
- [Hadoop - Winutils](https://github.com/steveloughran/winutils/tree/master)<br />
- [Java (versão 8 ou superior) - Oracle](https://www.oracle.com/java/technologies/downloads/#java8)<br />
<br />
<div style="text-align: justify">
<strong>Cuidados:</strong><br /><br />
- Garanta que o PATH do Spark, Hadoop e Java estejam corretamente configurados.<br />
- Após instalar os componentes necessários, execute o comando pip install pyspark.
<br /><br />
<strong>Sites com um bom passo a passo:</strong><br /><br />
</div>
[Instalação de PySpark - Medium](https://medium.com/tinghaochen/how-to-install-pyspark-locally-94501eefe421)<br />
[Executando PySpark no Windows - SparkByExamples](https://sparkbyexamples.com/pyspark/how-to-install-and-run-pyspark-on-windows/)<br />
[Guia de Instalação do Spark - CrayonData](- https://crayondata.ai/guide-to-install-spark-and-use-pyspark-from-jupyter-in-windows/ )
<br />
