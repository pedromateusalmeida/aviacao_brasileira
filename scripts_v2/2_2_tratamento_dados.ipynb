{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "504e07cf-701b-4c45-a852-b1989a71f347",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f15609a6-ba9f-4ecf-86a5-bce6b4aefa9b",
   "metadata": {},
   "source": [
    "# Pacote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6034b19-3585-4615-a296-2f26a30b2b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import chardet\n",
    "import glob\n",
    "from unidecode import unidecode\n",
    "import os\n",
    "import Levenshtein as lev\n",
    "import csv \n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe29d84-05ed-4ad5-a4c3-1540053ce6b0",
   "metadata": {},
   "source": [
    "# Funções"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3463c4e-4fb8-452b-86fb-ceb7221da2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_encoding(file_pattern_or_path, num_bytes=10000):\n",
    "    \"\"\"\n",
    "    Detecta a codificação do arquivo ou arquivos fornecidos.\n",
    "    \n",
    "    Parâmetros:\n",
    "        file_pattern_or_path (str): Caminho ou padrão do arquivo para detecção.\n",
    "        num_bytes (int, opcional): Número de bytes para ler para a detecção. Padrão é 10000.\n",
    "    \n",
    "    Retorna:\n",
    "        dict: Dicionário com caminho do arquivo como chave e codificação detectada como valor.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Encontrar arquivos que correspondem ao padrão ou caminho fornecido.\n",
    "    files = glob.glob(file_pattern_or_path)\n",
    "    encodings = {}\n",
    "\n",
    "    # Iterar sobre cada arquivo encontrado.\n",
    "    for file_path in files:\n",
    "        # Abrir arquivo em modo binário e ler os primeiros 'num_bytes' bytes.\n",
    "        with open(file_path, 'rb') as f:\n",
    "            rawdata = f.read(num_bytes)\n",
    "            # Detectar a codificação do fragmento lido e armazenar no dicionário.\n",
    "            encodings[file_path] = chardet.detect(rawdata)[\"encoding\"]\n",
    "    \n",
    "    return encodings\n",
    "\n",
    "def is_delayed(row):\n",
    "    \"\"\"\n",
    "    Determina se um voo está atrasado ou pontual com base na diferença de tempo entre a partida prevista e a real.\n",
    "\n",
    "    Parâmetros:\n",
    "    row (pd.Series): Uma linha de um DataFrame que contém informações de partida do voo.\n",
    "\n",
    "    Retorna:\n",
    "    str: \"Atrasado\" se o voo estiver atrasado por mais de 15 minutos, caso contrário \"Pontual\".\n",
    "    \"\"\"\n",
    "    # Calcula a diferença de tempo entre a partida real e a prevista.\n",
    "    delta = row['Partida Real'] - row['Partida Prevista']\n",
    "    # Retorna \"Atrasado\" se a diferença for maior que 15 minutos, senão \"Pontual\".\n",
    "    return \"Atrasado\" if delta > pd.Timedelta(minutes=15) else \"Pontual\"\n",
    "\n",
    "def padronizar_nome_coluna(coluna):\n",
    "    \"\"\"\n",
    "    Padroniza o nome de uma coluna removendo acentos, transformando em minúsculas e substituindo espaços, hífens, \n",
    "    parênteses, pontos, vírgulas, porcentagens e barras por underscores ou removendo-os. Remove underscores duplicados.\n",
    "\n",
    "    Parâmetros:\n",
    "    coluna (str): Nome da coluna a ser padronizado.\n",
    "\n",
    "    Retorna:\n",
    "    str: Nome da coluna padronizado.\n",
    "    \"\"\"\n",
    "    from unidecode import unidecode\n",
    "\n",
    "    # Remover acentos do nome da coluna.\n",
    "    coluna = unidecode(coluna)\n",
    "    # Transformar todas as letras em minúsculas.\n",
    "    coluna = coluna.lower()\n",
    "    # Substituir espaços, hífens, parênteses, pontos, vírgulas, porcentagens, barras e barras invertidas por underscores ou removendo-os.\n",
    "    coluna = coluna.replace(' ', '_').replace('-', '_').replace('(', '_').replace(')', '_').replace('.', '_').replace(',', '_').replace('%', 'pcnt').replace('/', '').replace('\\\\', '')\n",
    "    # Substituir underscores duplicados por um único underscore.\n",
    "    while '__' in coluna:\n",
    "        coluna = coluna.replace('__', '_')\n",
    "\n",
    "    return coluna\n",
    "\n",
    "def calculate_time_delta(row, start_col, end_col):\n",
    "    \"\"\"\n",
    "    Calcula a diferença de tempo entre duas colunas de um DataFrame.\n",
    "\n",
    "    Parâmetros:\n",
    "    row (pd.Series): Uma linha do DataFrame.\n",
    "    start_col (str): Nome da coluna com o tempo inicial.\n",
    "    end_col (str): Nome da coluna com o tempo final.\n",
    "\n",
    "    Retorna:\n",
    "    pd.Timedelta: Diferença de tempo entre 'start_col' e 'end_col'.\n",
    "    \"\"\"\n",
    "    # Extrai os tempos iniciais e finais das colunas especificadas.\n",
    "    start_time = row[start_col]\n",
    "    end_time = row[end_col]\n",
    "    \n",
    "    # Verifica se algum dos tempos é NaT (Not a Time) e retorna 0 se verdadeiro.\n",
    "    if pd.isna(start_time) or pd.isna(end_time):\n",
    "        return 0\n",
    "    \n",
    "    # Calcula e retorna a diferença absoluta de tempo entre os dois tempos.\n",
    "    delta = abs(end_time - start_time)\n",
    "    return delta\n",
    "\n",
    "def calculate_time_int(row, start_col, end_col):\n",
    "    \"\"\"\n",
    "    Calcula a diferença de tempo em minutos entre duas colunas de um DataFrame.\n",
    "\n",
    "    Parâmetros:\n",
    "    row (pd.Series): Uma linha do DataFrame.\n",
    "    start_col (str): Nome da coluna com o tempo inicial.\n",
    "    end_col (str): Nome da coluna com o tempo final.\n",
    "\n",
    "    Retorna:\n",
    "    int: Diferença de tempo em minutos entre 'start_col' e 'end_col'.\n",
    "    \"\"\"\n",
    "    # Extrai os tempos iniciais e finais das colunas especificadas.\n",
    "    start_time = row[start_col]\n",
    "    end_time = row[end_col]\n",
    "    \n",
    "    # Verifica se algum dos tempos é NaT (Not a Time) e retorna 0 se verdadeiro.\n",
    "    if pd.isna(start_time) or pd.isna(end_time):\n",
    "        return 0\n",
    "    \n",
    "    # Calcula a diferença de tempo, converte para segundos e depois para minutos.\n",
    "    delta = abs(end_time - start_time)\n",
    "    return int(delta.total_seconds() / 60)\n",
    "\n",
    "def encontrar_coluna_similar(coluna, colunas_padrao, limiar=8):\n",
    "    \"\"\"\n",
    "    Encontra a coluna mais similar a um dado nome de coluna, baseado em uma medida de distância.\n",
    "\n",
    "    Args:\n",
    "    coluna (str): Nome da coluna a ser comparada.\n",
    "    colunas_padrao (list): Lista de nomes de colunas padrão para comparação.\n",
    "    limiar (int, optional): Limiar de distância para considerar uma coluna similar. Default é 8.\n",
    "\n",
    "    Etapas:\n",
    "    1. Iterar sobre cada coluna padrão.\n",
    "    2. Calcular a distância de Levenshtein entre a coluna e cada coluna padrão.\n",
    "    3. Se a distância for menor ou igual ao limiar, retornar a coluna padrão correspondente.\n",
    "    4. Se nenhuma coluna padrão satisfizer o critério, retornar o nome da coluna original.\n",
    "\n",
    "    Returns:\n",
    "    str: O nome da coluna mais similar dentre as colunas padrão, ou o próprio nome da coluna se nenhuma for suficientemente similar.\n",
    "    \"\"\"\n",
    "     # Itera sobre cada coluna padrão na lista fornecida.\n",
    "    for padrao in colunas_padrao:\n",
    "        # Calcula a distância de Levenshtein entre a coluna e a coluna padrão atual.\n",
    "        # A função lev.distance() é assumida como uma função predefinida ou importada para calcular esta distância.\n",
    "        if lev.distance(coluna, padrao) <= limiar:\n",
    "            # Se a distância for menor ou igual ao limiar, retorna a coluna padrão como correspondente.\n",
    "            return padrao\n",
    "    # Se nenhuma coluna padrão corresponder dentro do limiar, retorna o nome da coluna original.\n",
    "    return coluna\n",
    "\n",
    "# Função para detectar o delimitador mais adequado\n",
    "def detectar_delimitador(filename, encoding='utf-8', num_lines=10):\n",
    "    \"\"\"\n",
    "    Detecta o delimitador mais adequado para um arquivo CSV.\n",
    "\n",
    "    Args:\n",
    "    filename (str): Nome do arquivo a ser analisado.\n",
    "    encoding (str, optional): Codificação do arquivo. Default é 'utf-8'.\n",
    "    num_lines (int, optional): Número de linhas a serem lidas para a detecção do delimitador. Default é 10.\n",
    "\n",
    "    Etapas:\n",
    "    1. Definir uma lista de delimitadores possíveis.\n",
    "    2. Ler as primeiras linhas do arquivo, testando cada delimitador possível.\n",
    "    3. Identificar o delimitador que resulta no maior número de campos (colunas) por linha.\n",
    "    4. Retornar o delimitador que maximiza o número de campos.\n",
    "\n",
    "    Returns:\n",
    "    str: O delimitador mais adequado encontrado no arquivo. Se nenhum delimitador adequado for encontrado, retorna None.\n",
    "    \"\"\"\n",
    "    # Define uma lista de delimitadores possíveis para testar no arquivo.\n",
    "    delimitadores_possiveis = [',', ';', '\\t', '|']\n",
    "    # Inicializa variáveis para armazenar o delimitador com o máximo de campos e o número máximo de campos.\n",
    "    max_delimiter = None\n",
    "    max_fields = 1\n",
    "\n",
    "    # Abre o arquivo com o nome e codificação especificados.\n",
    "    with open(filename, 'r', encoding=encoding) as file:\n",
    "        # Testa cada delimitador possível.\n",
    "        for delimiter in delimitadores_possiveis:\n",
    "            # Retorna ao início do arquivo antes de testar um novo delimitador.\n",
    "            file.seek(0)\n",
    "            # Cria um leitor CSV com o delimitador atual.\n",
    "            reader = csv.reader(file, delimiter=delimiter)\n",
    "            # Itera sobre as linhas do arquivo até o limite especificado.\n",
    "            for i, row in enumerate(reader):\n",
    "                # Interrompe a leitura após um determinado número de linhas.\n",
    "                if i >= num_lines:\n",
    "                    break\n",
    "                # Atualiza o delimitador e o número máximo de campos se este delimitador resultar em mais campos.\n",
    "                if len(row) > max_fields:\n",
    "                    max_fields = len(row)\n",
    "                    max_delimiter = delimiter\n",
    "\n",
    "    # Retorna o delimitador que resultou no maior número de campos por linha.\n",
    "    return max_delimiter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd31f6cd-8c80-4a69-a886-ae34348a0707",
   "metadata": {},
   "source": [
    "# Carregando dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c043bca8-9a11-4e75-830a-679c63f48917",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Carregamento dos Dados dos Aeroportos ---\n",
    "# Definindo o caminho para o arquivo CSV dos glossários de aeródromos.\n",
    "file_path = \"dados_complementares_convertidos/glossario_de_aerodromo.csv\"\n",
    "\n",
    "# Detectando a codificação do arquivo de aeródromos para assegurar a leitura correta dos dados.\n",
    "file_encodings = detect_encoding(file_path)\n",
    "\n",
    "# Obtendo a codificação detectada para o arquivo específico.\n",
    "encoding = file_encodings[file_path]\n",
    "\n",
    "# Lendo o arquivo CSV com a codificação apropriada.\n",
    "# A codificação detectada é usada para lidar com possíveis caracteres especiais nos dados.\n",
    "df_aeroportos = pd.read_csv(file_path, sep=',', encoding=encoding)  # A codificação pode variar (ex: 'iso-8859-1', 'cp1252'), dependendo do arquivo.\n",
    "\n",
    "\n",
    "# --- Carregamento dos Dados das Companhias Aéreas ---\n",
    "# Definindo o caminho para o arquivo CSV dos glossários de empresas aéreas.\n",
    "file_path = \"dados_complementares_convertidos/glossario_de_empresas_aereas.csv\"\n",
    "\n",
    "# Detectando a codificação do arquivo das empresas aéreas.\n",
    "file_encodings = detect_encoding(file_path)\n",
    "\n",
    "# Obtendo a codificação detectada para este arquivo específico.\n",
    "encoding = file_encodings[file_path]\n",
    "\n",
    "# Lendo o arquivo CSV com a codificação apropriada.\n",
    "# Novamente, a codificação detectada é essencial para lidar com caracteres especiais.\n",
    "df_cia_aerea = pd.read_csv(file_path, sep=',', encoding=encoding)  # A codificação pode variar, semelhante ao arquivo de aeródromos.\n",
    "\n",
    "# --- Carregamento dos Dados das Companhias Aéreas ---\n",
    "# Definindo o caminho para o arquivo CSV com algumas informações de aeroportos.\n",
    "file_path = \"dados_tratados/dados_aeroportos_tratado.csv\"\n",
    "\n",
    "# Detectando a codificação do arquivo.\n",
    "file_encodings = detect_encoding(file_path)\n",
    "\n",
    "# Obtendo a codificação detectada para este arquivo específico.\n",
    "encoding = file_encodings[file_path]\n",
    "\n",
    "# Lendo o arquivo CSV com a codificação apropriada.\n",
    "# Novamente, a codificação detectada é essencial para lidar com caracteres especiais.\n",
    "df_aeroportos_2 = pd.read_csv(file_path, sep=',', encoding=encoding)  # A codificação pode variar, semelhante ao arquivo de aeródromos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "90965be9-7751-45a4-a40b-2c96f0ea8d4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carregando arquivo: 2022\\vra-01_2022.csv\n",
      "Arquivo 2022\\vra-01_2022.csv carregado com sucesso usando a codificação utf-8.\n",
      "Carregando arquivo: 2022\\vra-02_2022.csv\n",
      "Erro de decodificação com a codificação utf-8 no arquivo 2022\\vra-02_2022.csv: 'utf-8' codec can't decode byte 0xe9 in position 20: invalid continuation byte\n",
      "Arquivo 2022\\vra-02_2022.csv carregado com sucesso usando a codificação latin1.\n",
      "Carregando arquivo: 2022\\vra-03_2022.csv\n",
      "Erro de decodificação com a codificação utf-8 no arquivo 2022\\vra-03_2022.csv: 'utf-8' codec can't decode byte 0xe9 in position 20: invalid continuation byte\n",
      "Arquivo 2022\\vra-03_2022.csv carregado com sucesso usando a codificação latin1.\n",
      "Carregando arquivo: 2022\\vra-04_2022.csv\n",
      "Arquivo 2022\\vra-04_2022.csv carregado com sucesso usando a codificação utf-8.\n",
      "Carregando arquivo: 2022\\vra-05_2022.csv\n",
      "Arquivo 2022\\vra-05_2022.csv carregado com sucesso usando a codificação utf-8.\n",
      "Carregando arquivo: 2022\\vra-06_2022.csv\n",
      "Erro de decodificação com a codificação utf-8 no arquivo 2022\\vra-06_2022.csv: 'utf-8' codec can't decode byte 0xe9 in position 20: invalid continuation byte\n",
      "Arquivo 2022\\vra-06_2022.csv carregado com sucesso usando a codificação latin1.\n",
      "Carregando arquivo: 2022\\vra-07_2022.csv\n",
      "Arquivo 2022\\vra-07_2022.csv carregado com sucesso usando a codificação utf-8.\n",
      "Carregando arquivo: 2022\\vra-08_2022.csv\n",
      "Arquivo 2022\\vra-08_2022.csv carregado com sucesso usando a codificação utf-8.\n",
      "Carregando arquivo: 2022\\vra-09_2022.csv\n",
      "Arquivo 2022\\vra-09_2022.csv carregado com sucesso usando a codificação utf-8.\n",
      "Carregando arquivo: 2022\\vra-10_2022.csv\n",
      "Arquivo 2022\\vra-10_2022.csv carregado com sucesso usando a codificação utf-8.\n",
      "Carregando arquivo: 2022\\vra-11_2022.csv\n",
      "Arquivo 2022\\vra-11_2022.csv carregado com sucesso usando a codificação utf-8.\n",
      "Carregando arquivo: 2022\\vra-12_2022.csv\n",
      "Arquivo 2022\\vra-12_2022.csv carregado com sucesso usando a codificação utf-8.\n",
      "Todos os arquivos CSV foram carregados com sucesso.\n"
     ]
    }
   ],
   "source": [
    "mapeamento_colunas = {\n",
    "    'Código Autorização (DI)': 'Codigo DI',\n",
    "    'cd_di': 'Codigo DI',\n",
    "    'ICAO Empresa Aerea': 'ICAO Empresa Aérea',\n",
    "    'sg_empresa_icao': 'ICAO Empresa Aérea',\n",
    "    'Número Voo': 'Número Voo',\n",
    "    'NUmero Voo': 'Número Voo',\n",
    "    'Numero Voo': 'Número Voo',\n",
    "    'nr_voo': 'Número Voo',\n",
    "    'Código Tipo Linha': 'Código Tipo Linha',\n",
    "    'Codigo Tipo Linha': 'Código Tipo Linha',\n",
    "    'cd_tipo_linha': 'Código Tipo Linha',\n",
    "    'ICAO Aeródromo Origem': 'ICAO Aeródromo Origem',\n",
    "    'ICAO Aerodromo Origem': 'ICAO Aeródromo Origem',\n",
    "    'sg_icao_origem': 'ICAO Aeródromo Origem',\n",
    "    'ICAO Aeródromo Destino': 'ICAO Aeródromo Destino',\n",
    "    'ICAO Aerodromo Destino': 'ICAO Aeródromo Destino',\n",
    "    'sg_icao_destino': 'ICAO Aeródromo Destino',\n",
    "    'Partida Prevista': 'Partida Prevista',\n",
    "    'dt_partida_prevista': 'Partida Prevista',\n",
    "    'Partida Real': 'Partida Real',\n",
    "    'Código DI': 'Codigo DI',   \n",
    "    'Data Partida Real': 'Partida Real',\n",
    "    'Data Chegada Real': 'Chegada Real',\n",
    "    'Data Partida Prevista': 'Partida Prevista',\n",
    "    'Data Chegada Prevista': 'Chegada Prevista',\n",
    "    'dt_partida_real': 'Partida Real',\n",
    "    'Chegada Prevista': 'Chegada Prevista',\n",
    "    'dt_chegada_prevista': 'Chegada Prevista',\n",
    "    'Chegada Real': 'Chegada Real',\n",
    "    'dt_chegada_real': 'Chegada Real',\n",
    "    'Situação Voo': 'Situação Voo',\n",
    "    'Situacao Voo': 'Situação Voo',\n",
    "    'situacao': 'Situação Voo',\n",
    "    'Código Justificativa': 'Código Justificativa',\n",
    "    'Codigo Justificativa': 'Código Justificativa',\n",
    "    'cd_justificativa': 'Código Justificativa',\n",
    "    'ICAO Aer—dromo Origem': 'ICAO Aeródromo Origem',\n",
    "    'ICAO Aer—dromo Destino': 'ICAO Aeródromo Destino',\n",
    "    'Sigla ICAO Aeroporto Origem': 'ICAO Aeródromo Origem',\n",
    "    'Sigla ICAO Aeroporto Destino': 'ICAO Aeródromo Destino',\n",
    "    'Sigla ICAO Empresa Aérea': 'ICAO Empresa Aérea',\n",
    "}\n",
    "\n",
    "# Colunas padrão esperadas\n",
    "colunas_esperadas = [\n",
    "    'ICAO Empresa Aérea', 'Número Voo', 'Código Tipo Linha',\n",
    "    'ICAO Aeródromo Origem', 'ICAO Aeródromo Destino', 'Partida Prevista', 'Partida Real',\n",
    "    'Chegada Prevista', 'Chegada Real', 'Situação Voo', 'Código Justificativa', 'Codigo DI'\n",
    "]\n",
    "\n",
    "# Definindo o caminho para os arquivos CSV do ano de 2019.\n",
    "file_path = \"2022/*.csv\"\n",
    "\n",
    "# Detectando a codificação dos arquivos CSV\n",
    "file_encodings = detect_encoding(file_path)\n",
    "codificacoes_comuns = ['utf-8', 'latin1', 'ISO-8859-1', 'ascii','utf-32','utf-16']\n",
    "# Processamento dos arquivos CSV\n",
    "df_list = []\n",
    "for filename in glob.glob(file_path):\n",
    "    print(f\"Carregando arquivo: {filename}\")\n",
    "    for encoding in codificacoes_comuns:\n",
    "        try:\n",
    "            delimitador = detectar_delimitador(filename, encoding=encoding)\n",
    "            df = pd.read_csv(filename, encoding=encoding, sep=delimitador, low_memory=False, index_col=None)\n",
    "\n",
    "            # Renomear colunas com base no mapeamento\n",
    "            df.rename(columns=mapeamento_colunas, inplace=True, errors='ignore')\n",
    "\n",
    "            # Manter apenas as colunas esperadas que existem no DataFrame\n",
    "            colunas_existentes = [col for col in colunas_esperadas if col in df.columns]\n",
    "            df = df[colunas_existentes]\n",
    "\n",
    "            df_list.append(df)\n",
    "            print(f\"Arquivo {filename} carregado com sucesso usando a codificação {encoding}.\")\n",
    "            break\n",
    "        except UnicodeDecodeError as e:\n",
    "            print(f\"Erro de decodificação com a codificação {encoding} no arquivo {filename}: {e}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Erro ao carregar o arquivo {filename}: {e}\")\n",
    "            break\n",
    "\n",
    "# Concatenando todos os DataFrames em um único DataFrame para análise combinada.\n",
    "if df_list:\n",
    "    combined_df = pd.concat(df_list, ignore_index=True)\n",
    "    print(\"Todos os arquivos CSV foram carregados com sucesso.\")\n",
    "else:\n",
    "    print(\"Nenhum arquivo CSV foi encontrado ou carregado.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "ce6cc9a1-e0ff-4eb1-8a8a-8d6d386a52ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = combined_df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d8a938-a091-427e-b7c2-390b9245dc0a",
   "metadata": {},
   "source": [
    "## Dicionário de dados\n",
    "| Campo                         | Descrição                                                                                                   |\r\n",
    "|-------------------------------|-------------------------------------------------------------------------------------------------------------|\r\n",
    "| Sigla ICAO Empresa Aérea      | Sigla/Designador ICAO Empresa Aérea                                                                         |\r\n",
    "| Número Voo                    | Numeração do voo                                                                                            |\r\n",
    "| Código DI                     | Caractere usado para identificar o Dígito Identificador (DI) para cada etapa de voo                         |\r\n",
    "| Código Tipo Linha             | Caractere usado para identificar o Tipo de Linha realizada para cada etapa de voo                           |\r\n",
    "| Sigla ICAO Aeroporto Origem   | Sigla/Designador ICAO Aeroporto de Origem                                                                   |\r\n",
    "| Sigla ICAO Aeroporto Destino  | Sigla/Designador ICAO Aeroporto de Destino                                                                  |\r\n",
    "| Partida Prevista              | Data e horário da partida prevista informada pela empresa aérea, em horário de Brasília                      |\r\n",
    "| Partida Real                  | Data e horário da partida realizada informada pela empresa aérea, em horário de Brasília                     |\r\n",
    "| Chegada Prevista              | Data e horário da chegada prevista informada pela empresa aérea, em horário de Brasília                      |\r\n",
    "| Chegada Real                  | Data e horário da chegada realizada, informada pela empresa aérea, em horário de Brasília                    |\r\n",
    "| Situação do voo               | Campo informando a situação do voo: realizado, cancelado ou não informado.                                  |\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f78d08-0b16-4f3a-b17f-2f97b1c65f58",
   "metadata": {},
   "source": [
    "# Tratamento de dados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "509b051a-9054-47f4-ad73-33fbf4aefbbf",
   "metadata": {},
   "source": [
    "## Join com as tabelas complementares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "dad02cbf-88e5-4ddb-82e9-bb132d70e161",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparando DataFrames de Aeroportos para Mesclagem com o DataFrame Principal.\n",
    "\n",
    "# Criando cópias do DataFrame de aeroportos para uso separado como origem e destino.\n",
    "df_aeroportos_origem = df_aeroportos.copy()\n",
    "df_aeroportos_destino = df_aeroportos.copy()\n",
    "\n",
    "# Renomeando as colunas do DataFrame de aeroportos origem.\n",
    "# Isso é feito para evitar conflitos de nomes ao mesclar com o DataFrame principal.\n",
    "# Cada nome de coluna é acrescido de '_origem' para indicar que se refere ao aeroporto de origem do voo.\n",
    "df_aeroportos_origem.rename(columns={col: col + '_origem' for col in df_aeroportos_origem.columns}, inplace=True)\n",
    "\n",
    "# Renomeando as colunas do DataFrame de aeroportos destino de forma similar.\n",
    "# Aqui, '_destino' é acrescido para indicar que as colunas se referem ao aeroporto de destino.\n",
    "df_aeroportos_destino.rename(columns={col: col + '_destino' for col in df_aeroportos_destino.columns}, inplace=True)\n",
    "\n",
    "# Mesclando o DataFrame principal com o DataFrame de companhias aéreas.\n",
    "# A mesclagem é feita com base na coluna 'ICAO Empresa Aérea' do DataFrame principal\n",
    "# e na coluna 'Sigla OACI' do DataFrame das companhias aéreas.\n",
    "# A opção 'inner' assegura que apenas os registros presentes em ambos os DataFrames sejam mantidos.\n",
    "df = pd.merge(df, df_cia_aerea, left_on='ICAO Empresa Aérea', right_on='Sigla OACI', how='inner')\n",
    "\n",
    "# Mesclando o DataFrame resultante com o DataFrame de aeroportos origem.\n",
    "# A mesclagem utiliza 'ICAO Aeródromo Origem' do DataFrame principal e 'Sigla OACI_origem' do DataFrame de aeroportos origem.\n",
    "df = pd.merge(df, df_aeroportos_origem, left_on='ICAO Aeródromo Origem', right_on='Sigla OACI_origem', how='inner')\n",
    "\n",
    "# Mesclando o DataFrame resultante com o DataFrame de aeroportos destino.\n",
    "# Similar à etapa anterior, mas agora usando 'ICAO Aeródromo Destino' e 'Sigla OACI_destino'.\n",
    "df = pd.merge(df, df_aeroportos_destino, left_on='ICAO Aeródromo Destino', right_on='Sigla OACI_destino', how='inner')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b721bd3b-13d0-4046-8e5c-95568ec8283d",
   "metadata": {},
   "source": [
    "## Filtro de cia aerea "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "ce98fa33-e07e-4288-8880-7673e9bf1826",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrando o DataFrame para incluir apenas voos das empresas aéreas específicas.\n",
    "\n",
    "# Definindo a lista de códigos ICAO das empresas aéreas desejadas para o filtro.\n",
    "valores_filtrar = ['GLO', 'AZU', 'TAM']\n",
    "\n",
    "# Filtrando o DataFrame para manter apenas as linhas onde 'ICAO Empresa Aérea' corresponde aos valores na lista de filtro.\n",
    "df = df[df['ICAO Empresa Aérea'].isin(valores_filtrar)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b2bc35-e1ec-4185-a428-fdc0494f3050",
   "metadata": {},
   "source": [
    "## Datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "6518cece-c901-4256-8e1d-c3fa5f6f7212",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertendo colunas de datas e horas de partidas e chegadas para o formato datetime.\n",
    "\n",
    "# As seguintes colunas são convertidas para o tipo datetime usando o formato especificado '%d/%m/%Y %H:%M':\n",
    "# 'Partida Prevista', 'Partida Real', 'Chegada Prevista' e 'Chegada Real'.\n",
    "df['Partida Prevista'] = pd.to_datetime(df['Partida Prevista'], format='%d/%m/%Y %H:%M')\n",
    "df['Partida Real'] = pd.to_datetime(df['Partida Real'], format='%d/%m/%Y %H:%M')\n",
    "df['Chegada Prevista'] = pd.to_datetime(df['Chegada Prevista'], format='%d/%m/%Y %H:%M')\n",
    "df['Chegada Real'] = pd.to_datetime(df['Chegada Real'], format='%d/%m/%Y %H:%M')\n",
    "\n",
    "# Aplicando a função 'is_delayed' em cada linha para determinar se o voo está atrasado ou pontual.\n",
    "# O resultado é armazenado na nova coluna 'Status do Voo'.\n",
    "df['Status do Voo'] = df.apply(is_delayed, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f73769ea-bffc-4cde-8323-7bd86af4b0d9",
   "metadata": {},
   "source": [
    "### Criação de colunas com delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "a4d60c95-08bb-4ee8-a074-f049767ef42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicando a função para calcular o delta de tempo\n",
    "df['Delta Tempo Partida delta'] = df.apply(calculate_time_delta, axis=1, start_col='Partida Prevista', end_col='Partida Real')\n",
    "df['Delta Tempo Chegada delta'] = df.apply(calculate_time_delta, axis=1, start_col='Chegada Prevista', end_col='Chegada Real')\n",
    "\n",
    "# Aplicando a função para calcular o delta de tempo\n",
    "df['Delta Tempo Partida int'] = df.apply(calculate_time_int, axis=1, start_col='Partida Prevista', end_col='Partida Real')\n",
    "df['Delta Tempo Chegada int'] = df.apply(calculate_time_int, axis=1, start_col='Chegada Prevista', end_col='Chegada Real')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ceeee52-43bc-4e7e-8c09-5ce506a6a831",
   "metadata": {},
   "source": [
    "## Seleção de colunas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "b5cc4af6-737f-4d0f-b45b-bed1529c7438",
   "metadata": {},
   "outputs": [],
   "source": [
    "df= df[['Nome Empresas','Número Voo', 'Codigo DI','ICAO Aeródromo Origem', 'ICAO Aeródromo Destino',\n",
    " 'Código Tipo Linha', 'Partida Prevista', 'Partida Real',\n",
    " 'Chegada Prevista', 'Chegada Real', 'Situação Voo',\n",
    " 'Descrição_origem', 'País_origem', 'Continente_origem',\n",
    " 'Descrição_destino', 'País_destino', 'Continente_destino',\n",
    " 'Status do Voo', 'Delta Tempo Partida delta', 'Delta Tempo Chegada delta',\n",
    " 'Delta Tempo Partida int', 'Delta Tempo Chegada int', 'Cidade_origem',\n",
    " 'UF_origem', 'Cidade_destino', 'UF_destino']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c872483-459f-4b43-b16d-73bb3b15aada",
   "metadata": {},
   "source": [
    "## Removendo caracteres especiais e espaço do nome das colunas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "a92aea1c-b151-4a2e-8d90-fa1e7b67edae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar a função a cada nome de coluna\n",
    "df.columns = [padronizar_nome_coluna(col) for col in df.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4888cc72-27c0-4886-aecc-75c3d3cafd39",
   "metadata": {},
   "source": [
    "# Adiação de colunas mês, dia do mês e dia da semana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "7944516d-24d5-4e08-b816-d287271df3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extração de componentes de data das colunas de partida e chegada.\n",
    "\n",
    "# As seguintes operações são realizadas para extrair informações específicas das datas de partida:\n",
    "# 1. 'mes_partida': Extração do mês da 'partida_prevista'.\n",
    "# 2. 'dia_semana_partida': Extração do dia da semana da 'partida_prevista' (0 = Segunda-feira, 6 = Domingo).\n",
    "# 3. 'dia_mes_partida': Extração do dia do mês da 'partida_prevista'.\n",
    "df['mes_partida'] = df['partida_prevista'].dt.month\n",
    "df['dia_semana_partida'] = df['partida_prevista'].dt.dayofweek\n",
    "df['dia_mes_partida'] = df['partida_prevista'].dt.day\n",
    "df['hora_partida'] = df['partida_prevista'].dt.hour\n",
    "# Nota: As mesmas informações são extraídas para 'chegada_prevista', mas há um erro no código;\n",
    "# 'partida_prevista' está sendo usada ao invés de 'chegada_prevista'.\n",
    "# As variáveis 'mes_chegada', 'dia_semana_chegada', e 'dia_mes_chegada' devem ser ajustadas para usar 'chegada_prevista'.\n",
    "df['mes_chegada'] = df['chegada_prevista'].dt.month\n",
    "df['dia_semana_chegada'] = df['chegada_prevista'].dt.dayofweek\n",
    "df['dia_mes_chegada'] = df['chegada_prevista'].dt.day\n",
    "df['hora_chegada'] = df['chegada_prevista'].dt.hour\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a264f0f-65bd-446a-8324-6108cf792eb6",
   "metadata": {},
   "source": [
    "# Adicionando informações adicionais do Aeroporto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "1cd711a9-ce84-403c-bb87-632272d990b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparando DataFrames de Aeroportos para Mesclagem com o DataFrame Principal.\n",
    "\n",
    "# Criando cópias do DataFrame de aeroportos para uso separado como origem e destino.\n",
    "df_aeroportos_origem = df_aeroportos_2.copy()\n",
    "df_aeroportos_destino = df_aeroportos_2.copy()\n",
    "\n",
    "# Renomeando as colunas do DataFrame de aeroportos origem.\n",
    "# Isso é feito para evitar conflitos de nomes ao mesclar com o DataFrame principal.\n",
    "# Cada nome de coluna é acrescido de '_origem' para indicar que se refere ao aeroporto de origem do voo.\n",
    "df_aeroportos_origem.rename(columns={col: col + '_origem' for col in df_aeroportos_origem.columns}, inplace=True)\n",
    "\n",
    "# Renomeando as colunas do DataFrame de aeroportos destino de forma similar.\n",
    "# Aqui, '_destino' é acrescido para indicar que as colunas se referem ao aeroporto de destino.\n",
    "df_aeroportos_destino.rename(columns={col: col + '_destino' for col in df_aeroportos_destino.columns}, inplace=True)\n",
    "\n",
    "# Mesclando o DataFrame resultante com o DataFrame de aeroportos origem.\n",
    "# A mesclagem utiliza 'ICAO Aeródromo Origem' do DataFrame principal e 'Sigla OACI_origem' do DataFrame de aeroportos origem.\n",
    "df = pd.merge(df, df_aeroportos_origem, left_on='icao_aerodromo_origem', right_on='codigo_oaci_origem', how='left')\n",
    "\n",
    "# Mesclando o DataFrame resultante com o DataFrame de aeroportos destino.\n",
    "# Similar à etapa anterior, mas agora usando 'ICAO Aeródromo Destino' e 'Sigla OACI_destino'.\n",
    "df = pd.merge(df, df_aeroportos_destino, left_on='icao_aerodromo_destino', right_on='codigo_oaci_destino', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "169856da-51e1-445f-acb5-1c792817fb0e",
   "metadata": {},
   "source": [
    "# Padronização e seleção de colunas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "f128c655-8913-488c-8b3d-815506593055",
   "metadata": {},
   "outputs": [],
   "source": [
    "df =  df[['nome_empresas', 'numero_voo', 'codigo_di', 'codigo_tipo_linha',\n",
    " 'partida_prevista', 'partida_real', 'chegada_prevista',\n",
    " 'chegada_real', 'situacao_voo', 'descricao_origem', 'pais_origem',\n",
    " 'continente_origem', 'descricao_destino', 'pais_destino',\n",
    " 'continente_destino', 'status_do_voo', 'delta_tempo_partida_delta',\n",
    " 'delta_tempo_chegada_delta', 'delta_tempo_partida_int', 'delta_tempo_chegada_int',\n",
    " 'cidade_origem', 'uf_origem_x', 'cidade_destino', 'uf_destino_x', 'mes_partida',\n",
    " 'dia_semana_partida', 'dia_mes_partida', 'hora_partida',\n",
    " 'mes_chegada', 'dia_semana_chegada', 'dia_mes_chegada',\n",
    " 'hora_chegada',  'altitude_origem', 'latgeopoint_origem',\n",
    " 'longeopoint_origem', 'latitude_aero_origem', 'longitude_aero_origem',\n",
    " 'altitude_destino', 'latgeopoint_destino', 'longeopoint_destino',\n",
    " 'latitude_aero_destino', 'longitude_aero_destino']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "ff5d8d98-92d8-4073-a423-4d710039665b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_name(name):\n",
    "    # Remove content inside parentheses\n",
    "    name = pd.Series(name).replace(r'\\(.*?\\)', '', regex=True).str.strip()\n",
    "\n",
    "    # Remove accents and special characters\n",
    "    return name.str.normalize('NFKD').str.encode('ascii', errors='ignore').str.decode('utf-8').str.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "348efcc0-da36-46ac-b7a5-5cf5383c4e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying the cleaning function to the 'uf' column\n",
    "df['cidade_origem'] = clean_name(df['cidade_origem'])\n",
    "df['cidade_destino'] = clean_name(df['cidade_destino'])\n",
    "df['descricao_origem'] = clean_name(df['descricao_origem'])\n",
    "df['descricao_destino'] = clean_name(df['descricao_destino'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e16efa6-9bd3-4948-8ed8-b81377573dc3",
   "metadata": {},
   "source": [
    "# Criando coluna com as principais rotas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "0cb46c02-526d-4aff-ab18-28ec93c449e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criação da variavel rota (aeroporto origem + aeroporto destino). Observar as rotas mais problemas de atraso e cancelamento\n",
    "df['rota'] = df['descricao_origem'] + \" -> \" + df['descricao_destino']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89679970-ea06-4884-bf1f-21e07e781abc",
   "metadata": {},
   "source": [
    "# Salvando os dados tratatos para realizar o join com dados meteorologicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "f4c3a5a4-7b33-451a-8dc8-efaf2e7fa6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir o caminho do diretório e do arquivo CSV\n",
    "diretorio = 'dados_tratados'\n",
    "nome_arquivo = 'historico_voo_tratados_2023.csv'\n",
    "caminho_completo = os.path.join(diretorio, nome_arquivo)\n",
    "\n",
    "# Verificar se o diretório existe. Se não, criar o diretório\n",
    "if not os.path.exists(diretorio):\n",
    "    os.makedirs(diretorio)\n",
    "\n",
    "# Salvar o DataFrame no arquivo CSV\n",
    "df.to_csv(caminho_completo, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9c5a5a-0a08-4c69-b976-670f3c7ecc67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir o caminho do diretório e do arquivo CSV\n",
    "diretorio = 'dados_tratados'\n",
    "nome_arquivo = 'historico_voo_tratados_2019.parquet'\n",
    "caminho_completo = os.path.join(diretorio, nome_arquivo)\n",
    "\n",
    "# Verificar se o diretório existe. Se não, criar o diretório\n",
    "if not os.path.exists(diretorio):\n",
    "    os.makedirs(diretorio)\n",
    "\n",
    "# Salvar o DataFrame no arquivo CSV\n",
    "df.to_parquet(caminho_completo, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "8b0ec4d8-6c93-4c7f-bf86-d4be14518a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "diretorio = 'dados_tratados'\n",
    "nome_arquivo = 'historico_voo_tratados_2019.parquet'\n",
    "caminho_completo = os.path.join(diretorio, nome_arquivo)\n",
    "df.to_parquet(caminho_completo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6dba2c-5e44-4e16-b348-4728d7be96f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
